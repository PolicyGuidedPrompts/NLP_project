We added two meanings to special action:
stop adding in context examples and generate output.
In practice:
special action need to mean stop adding examples only. generating happens regardless.

Policy started choosing same action for all examples.

gpt2 shit

chooses same action all the time

The policy seems to not really care about if question itself but rather put more attention to how the question answer is
formatted

put two different logic of softmax temperature in order to encourage exploration

see if can prove correlation between prompt length and better predictions

prompt shorter than 300 results in YES/NO instead of True/False

Fact -> Question > Answer resulted in "True Facts" instead of "True", switch the order Question -> Fact -> Answer helped

longer prompts takes longer to get stuck on a specific action

Prompt too long (more than 500 tokens cause poor predictions, instead of True/False continue sentence not even starting with True/False)